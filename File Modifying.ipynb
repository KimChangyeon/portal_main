{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T04:55:45.626558Z",
     "start_time": "2020-03-10T04:55:45.153173Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T04:56:30.527550Z",
     "start_time": "2020-03-10T04:56:30.180913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUPLICATED INFO FROM 20090607.csv to 20190404.csv\n",
      "NAVER FROM 20000202.json to 20191002.json\n",
      "1788\n",
      "NAVER MAIN FROM 20140430.json to 20190404.json\n",
      "NAVER COMMENT FROM 20151208.json to 20190706.json\n",
      "SPLITED MAIN FROM 20151208.csv to 20190404.csv\n"
     ]
    }
   ],
   "source": [
    "dup_path = '../news data/articles/20200304_duplicated/'\n",
    "dup_list = os.listdir(dup_path)[1:]\n",
    "print('DUPLICATED INFO FROM {} to {}'.format(dup_list[0], dup_list[-1]))\n",
    "\n",
    "naver_path = '../news data/articles/all_daily_articles_naver/'\n",
    "naver_list = os.listdir(naver_path)\n",
    "print('NAVER FROM {} to {}'.format(naver_list[0], naver_list[-1]))\n",
    "\n",
    "with open('../pilgrim data/sid_to_cat.csv', 'r', encoding = 'utf-8') as g:\n",
    "    reader = csv.reader(g)\n",
    "    sid_to_cat = {line[0]: line[1] for line in reader}\n",
    "    del sid_to_cat['\\ufeffsid']\n",
    "\n",
    "naver_main_path = '../news data/main/main_naver/main/'\n",
    "naver_main_list = os.listdir(naver_main_path)\n",
    "idx = naver_main_list.index('2014-04-30.json')\n",
    "print(idx)\n",
    "naver_main_list_original = naver_main_list[idx:]\n",
    "naver_main_list = list(map(lambda x: x[:4] + x[5:7] + x[8:], naver_main_list_original))\n",
    "print('NAVER MAIN FROM {} to {}'.format(naver_main_list[0], naver_main_list[-1]))\n",
    "\n",
    "naver_comment_path = '../news data/comments/daily_comments/'\n",
    "naver_comment_list = os.listdir(naver_comment_path)[:-1]\n",
    "print('NAVER COMMENT FROM {} to {}'.format(naver_comment_list[0], naver_comment_list[-1]))\n",
    "\n",
    "splited_path = '../news data/articles/20200304_comment_split/'\n",
    "splited_list = os.listdir(splited_path)[1:]\n",
    "print('SPLITED MAIN FROM {} to {}'.format(splited_list[0], splited_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T03:21:43.164867Z",
     "start_time": "2020-03-10T03:21:43.152841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20141231.json',\n",
       " '20151231.json',\n",
       " '20161231.json',\n",
       " '20171231.json',\n",
       " '20181231.json']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_last = []\n",
    "for day in naver_main_list:\n",
    "    if day[4:8] == '1231':\n",
    "        year_last.append(day)\n",
    "        \n",
    "year_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T03:43:25.004143Z",
     "start_time": "2020-03-10T03:43:22.615461Z"
    }
   },
   "outputs": [],
   "source": [
    "for day in year_last:\n",
    "    df = pd.read_csv(dup_path + day[:8]+'.csv', dtype = object, index_col = False)\n",
    "\n",
    "    def year_change(time):\n",
    "        time = datetime.datetime.fromisoformat(time)\n",
    "        yr = time.year\n",
    "        time = time.replace(year = yr + 1)\n",
    "        return datetime.datetime.strftime(time, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    df.loc[(df['naver_mainDate'].notna()) & (df.naver_mainDate.str.contains('-')), 'naver_main_exposed_last'] = \\\n",
    "    df.loc[(df['naver_mainDate'].notna()) & (df.naver_mainDate.str.contains('-')), 'naver_main_exposed_last'].apply(lambda x: year_change(x))\n",
    "    df.loc[(df['naver_mainDate'].notna()) & (df.naver_mainDate.str.contains('-'))]\n",
    "    df\n",
    "\n",
    "    def main_date (start, end):\n",
    "        start_day = start[:4]+start[5:7]+start[8:10]\n",
    "        end_day = end[:4]+end[5:7]+end[8:10]\n",
    "        return start_day + '-' + end_day\n",
    "    df.loc[(df['naver_mainDate'].notna()) & (df.naver_mainDate.str.contains('-')), 'naver_mainDate'] = \\\n",
    "    df.loc[(df['naver_mainDate'].notna()) & (df.naver_mainDate.str.contains('-'))].apply(lambda x: main_date(x['naver_main_exposed_first'], x['naver_main_exposed_last']), axis = 1)\n",
    "    df.loc[(df['naver_mainDate'].notna()) & (df.naver_mainDate.str.contains('-'))]\n",
    "\n",
    "    df.to_csv(dup_path + day[:8]+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T05:29:45.340526Z",
     "start_time": "2020-03-10T05:29:43.724772Z"
    }
   },
   "outputs": [],
   "source": [
    "year_last = []\n",
    "dup_path = '../news data/articles/20200310_duplicated/'\n",
    "dup_path_org = '../news data/articles/20200304_duplicated 2/'\n",
    "for day in splited_list:\n",
    "    if day[4:8] == '1231':\n",
    "        year_last.append(day)\n",
    "        \n",
    "for day in year_last:\n",
    "    df = pd.read_csv(dup_path_org + day[:8]+'.csv', dtype = object, index_col = False)\n",
    "\n",
    "    def year_change(time):\n",
    "        time = datetime.datetime.fromisoformat(time)\n",
    "        yr = time.year\n",
    "        time = time.replace(year = yr + 1)\n",
    "        return datetime.datetime.strftime(time, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    df.loc[(df['naver_mainDate'].notna()) & (df.naver_mainDate.str.contains('-')), 'naver_main_exposed_last'] = \\\n",
    "    df.loc[(df['naver_mainDate'].notna()) & (df.naver_mainDate.str.contains('-')), 'naver_main_exposed_last'].apply(lambda x: year_change(x))\n",
    "    df.loc[(df['naver_mainDate'].notna()) & (df.naver_mainDate.str.contains('-'))]\n",
    "    df\n",
    "\n",
    "    def main_date (start, end):\n",
    "        start_day = start[:4]+start[5:7]+start[8:10]\n",
    "        end_day = end[:4]+end[5:7]+end[8:10]\n",
    "        return start_day + '-' + end_day\n",
    "    \n",
    "    df.loc[(df['naver_mainDate'].notna()) & (df.naver_mainDate.str.contains('-')), 'naver_mainDate'] = \\\n",
    "    df.loc[(df['naver_mainDate'].notna()) & (df.naver_mainDate.str.contains('-'))].apply(lambda x: main_date(x['naver_main_exposed_first'], x['naver_main_exposed_last']), axis = 1)\n",
    "    df.loc[(df['naver_mainDate'].notna()) & (df.naver_mainDate.str.contains('-'))]\n",
    "\n",
    "    df.to_csv(dup_path + day[:8]+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T03:41:33.506897Z",
     "start_time": "2020-03-10T03:41:33.468202Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[(df['naver_mainDate'].notna()) & (df.naver_mainDate.str.contains('-')), 'naver_mainDate'] = \\\n",
    "df.loc[(df['naver_mainDate'].notna()) & (df.naver_mainDate.str.contains('-'))].apply(lambda x: main_date(x['naver_main_exposed_first'], x['naver_main_exposed_last']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T04:07:24.197607Z",
     "start_time": "2020-03-10T04:07:24.192388Z"
    }
   },
   "outputs": [],
   "source": [
    "def datetime_change (st, delimiter = '-'):\n",
    "    if isinstance(st, float):\n",
    "        return st\n",
    "    \n",
    "    if delimiter in st:\n",
    "        splited = st.split(delimiter)\n",
    "        new_splited = []\n",
    "        for s in splited:\n",
    "            new_splited.append(s[:4] + '-' + s[4:6] + '-' + s[6:])\n",
    "        return '~'.join(new_splited)\n",
    "    else:\n",
    "        return st[:4] + '-' + st[4:6] + '-' + st[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T05:30:27.868202Z",
     "start_time": "2020-03-10T05:30:26.205581Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.43it/s]\n"
     ]
    }
   ],
   "source": [
    "def datetime_change (st, delimiter = '-'):\n",
    "    if isinstance(st, float):\n",
    "        return st\n",
    "    \n",
    "    if delimiter in st:\n",
    "        splited = st.split(delimiter)\n",
    "        new_splited = []\n",
    "        for s in splited:\n",
    "            new_splited.append(s[:4] + '-' + s[4:6] + '-' + s[6:])\n",
    "        return '~'.join(new_splited)\n",
    "    else:\n",
    "        return st[:4] + '-' + st[4:6] + '-' + st[6:]\n",
    "    \n",
    "from tqdm import tqdm\n",
    "dup_path_org = '../news data/articles/20200304_duplicated 2/'\n",
    "dup_path = '../news data/articles/20200310_duplicated/'\n",
    "for day in tqdm(year_last):\n",
    "    df = pd.read_csv(dup_path + day, dtype = object, index_col = False)\n",
    "    if day < '20140430.csv':\n",
    "        df['naver_mainDate'] = df['naver_mainDate'].apply(lambda x: datetime_change(x, ','))\n",
    "        df['daum_mainDate'] = df['daum_mainDate'].apply(lambda x: datetime_change(x, ','))\n",
    "    else:\n",
    "        df['naver_mainDate'] = df['naver_mainDate'].apply(lambda x: datetime_change(x, '-'))\n",
    "        df['daum_mainDate'] = df['daum_mainDate'].apply(lambda x: datetime_change(x, '-'))\n",
    "    df.to_csv(dup_path + day, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T04:08:02.098987Z",
     "start_time": "2020-03-10T04:08:01.991973Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(dup_path + '20101005.csv', dtype = object, index_col = False)\n",
    "df['naver_mainDate'] = df['naver_mainDate'].apply(lambda x: datetime_change(x, ','))\n",
    "df['daum_mainDate'] = df['daum_mainDate'].apply(lambda x: datetime_change(x, ','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T04:08:03.178918Z",
     "start_time": "2020-03-10T04:08:03.173547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '2010-10-05~2010-10-06', '2010-10-05'], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['naver_mainDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
